# 5号艇の複勝予測に関するドキュメント
最良のハイパーパラメーター: {'bootstrap': False, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}
カスタム閾値: 0.1
Accuracy: 0.4070711896798853
AUC Score: 0.6912839512542641
Classification Report:
              precision    recall  f1-score   support

           0       0.94      0.08      0.15      1342
           1       0.38      0.99      0.55       751

    accuracy                           0.41      2093
   macro avg       0.66      0.54      0.35      2093
weighted avg       0.74      0.41      0.29      2093

Confusion Matrix:
[[ 108 1234]
 [   7  744]]
カスタム閾値: 0.2
Accuracy: 0.5007166746297181
AUC Score: 0.6912839512542641
Classification Report:
              precision    recall  f1-score   support

           0       0.84      0.27      0.41      1342
           1       0.41      0.91      0.57       751

    accuracy                           0.50      2093
   macro avg       0.63      0.59      0.49      2093
weighted avg       0.69      0.50      0.47      2093

Confusion Matrix:
[[364 978]
 [ 67 684]]
カスタム閾値: 0.30000000000000004
Accuracy: 0.6115623506927855
AUC Score: 0.6912839512542641
Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.55      0.65      1342
           1       0.47      0.72      0.57       751

    accuracy                           0.61      2093
   macro avg       0.63      0.63      0.61      2093
weighted avg       0.67      0.61      0.62      2093

Confusion Matrix:
[[741 601]
 [212 539]]
カスタム閾値: 0.4
Accuracy: 0.6588628762541806
AUC Score: 0.6912839512542641
Classification Report:
              precision    recall  f1-score   support

           0       0.74      0.72      0.73      1342
           1       0.52      0.56      0.54       751

    accuracy                           0.66      2093
   macro avg       0.63      0.64      0.63      2093
weighted avg       0.66      0.66      0.66      2093

Confusion Matrix:
[[961 381]
 [333 418]]
カスタム閾値: 0.5
Accuracy: 0.6660296225513617
AUC Score: 0.6912839512542641
Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.82      0.76      1342
           1       0.55      0.40      0.46       751

    accuracy                           0.67      2093
   macro avg       0.63      0.61      0.61      2093
weighted avg       0.65      0.67      0.65      2093

Confusion Matrix:
[[1097  245]
 [ 454  297]]
カスタム閾値: 0.6000000000000001
Accuracy: 0.6789297658862876
AUC Score: 0.6912839512542641
Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.92      0.79      1342
           1       0.63      0.26      0.36       751

    accuracy                           0.68      2093
   macro avg       0.66      0.59      0.57      2093
weighted avg       0.67      0.68      0.63      2093

Confusion Matrix:
[[1229  113]
 [ 559  192]]
カスタム閾値: 0.7000000000000001
Accuracy: 0.6497849976110845
AUC Score: 0.6912839512542641
Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.98      0.78      1342
           1       0.62      0.06      0.11       751

    accuracy                           0.65      2093
   macro avg       0.63      0.52      0.45      2093
weighted avg       0.64      0.65      0.54      2093

Confusion Matrix:
[[1313   29]
 [ 704   47]]
カスタム閾値: 0.8
C:\Users\atsuk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\metrics\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
C:\Users\atsuk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\metrics\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
C:\Users\atsuk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\metrics\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Accuracy: 0.6411849020544673
AUC Score: 0.6912839512542641
Classification Report:
              precision    recall  f1-score   support

           0       0.64      1.00      0.78      1342
           1       0.00      0.00      0.00       751

    accuracy                           0.64      2093
   macro avg       0.32      0.50      0.39      2093
weighted avg       0.41      0.64      0.50      2093

Confusion Matrix:
[[1342    0]
 [ 751    0]]
カスタム閾値: 0.9
C:\Users\atsuk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\metrics\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
C:\Users\atsuk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\metrics\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
C:\Users\atsuk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\metrics\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Accuracy: 0.6411849020544673
AUC Score: 0.6912839512542641
Classification Report:
              precision    recall  f1-score   support

           0       0.64      1.00      0.78      1342
           1       0.00      0.00      0.00       751

    accuracy                           0.64      2093
   macro avg       0.32      0.50      0.39      2093
weighted avg       0.41      0.64      0.50      2093

Confusion Matrix:
[[1342    0]
 [ 751    0]]
C:\Users\atsuk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\metrics\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
C:\Users\atsuk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\metrics\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
C:\Users\atsuk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\sklearn\metrics\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Accuracy: 0.6411849020544673
AUC Score: 0.6912839512542641
Classification Report:
              precision    recall  f1-score   support

           0       0.64      1.00      0.78      1342
           1       0.00      0.00      0.00       751

    accuracy                           0.64      2093
   macro avg       0.32      0.50      0.39      2093
weighted avg       0.41      0.64      0.50      2093

Confusion Matrix:
[[1342    0]
 [ 751    0]]
モデルのトレーニングが完了しました
             特徴量       重要度
2      全国勝率_Zスコア  0.271209
3    全国2連対率_Zスコア  0.197525
7      当地勝率_Zスコア  0.127509
6    当地2連対率_Zスコア  0.111995
8     展示タイム_Zスコア  0.090395
4  モーター2連対率_Zスコア  0.079423
5   ボート2連対率_Zスコア  0.070824
1             体重  0.037860
0             天気  0.013258



# 考察
用語解説
正確性（Accuracy）：モデルが全体的にどれだけ正確に予測できるかを示します。
精度（Precision）：正と予測された中で、実際に正である割合。
再現率（Recall）：実際に正であるデータの中で、正と予測された割合。
F1スコア：精度と再現率の調和平均で、バランスの取れたモデルの性能を示します。

どれが大切か考える。
Recallが高いほど、実際の1の結果を多めに捉える。そう考えると、1のRecallが高く、バランスも良い通常時のモデルがよさそう？
0の精度が低い（0と予想したとき50%しか正解していない）のは少し問題？

2連対率については、あってもなくても結果がそこまで変わらないので、なくてよさそう。

枠ごとの特徴量は偏差値（Zスコア）のほうがいい。

全国勝率も当地勝率もあった方がいい。


勝率と2連率どちらを用いるかは非常に難しい。

1号艇が複勝する場合の予測の正確さを最優先する場合、通常時のモデルが適している。
これは、高いAccuracyと非常に高いクラス1の再現率により、ほとんどの複勝を正確に捉えることができるためである。

クラス0とクラス1の成績のバランスを取ることが重要な場合（つまり、1号艇が複勝しない場合の予測も重要視する場合）、2連率のみのモデルが適している。
このモデルは、両クラスの成績が比較的均等であり、よりバランスの取れた予測を提供する。

多く買ってたくさん的中を目指すか、絞って穴を狙うかに近い。





